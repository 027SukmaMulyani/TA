{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f218f3e",
   "metadata": {},
   "source": [
    "# 1. Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f184a",
   "metadata": {},
   "source": [
    "## 1.1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d417560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Union, Tuple, List, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac05496",
   "metadata": {},
   "source": [
    "## 1.2 Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79225b1",
   "metadata": {},
   "source": [
    "### 1.2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3da489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path: str, text_column: str, label_column: str, \n",
    "                  encoding: str = 'utf-8') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Import data dari file CSV\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path ke file CSV\n",
    "        text_column: Nama kolom yang berisi teks\n",
    "        label_column: Nama kolom yang berisi label/kelas\n",
    "        encoding: Encoding file (default: utf-8)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame dengan data yang sudah diload\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, encoding=encoding)\n",
    "        \n",
    "        # Validasi kolom yang diperlukan ada\n",
    "        if text_column not in data.columns:\n",
    "            raise ValueError(f\"Kolom '{text_column}' tidak ditemukan\")\n",
    "        if label_column not in data.columns:\n",
    "            raise ValueError(f\"Kolom '{label_column}' tidak ditemukan\")\n",
    "        \n",
    "        # Bersihkan data dari nilai kosong\n",
    "        data = data.dropna(subset=[text_column, label_column])\n",
    "        \n",
    "        print(f\"Data berhasil diload: {len(data)} sampel\")\n",
    "        print(f\"Distribusi kelas:\")\n",
    "        print(data[label_column].value_counts())\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saat load CSV: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21e546",
   "metadata": {},
   "source": [
    "### 1.2.2 Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0f8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_data(data: pd.DataFrame, n_samples: int = 5, include_stats: bool = True) -> Dict[str, Any]:\n",
    "   preview_info = {\n",
    "       'dataset_shape': data.shape,\n",
    "       'column_names': list(data.columns),\n",
    "       'data_types': data.dtypes.to_dict(),\n",
    "       'memory_usage': f\"{data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\",\n",
    "       'head_samples': data.head(n_samples),\n",
    "       'tail_samples': data.tail(n_samples),\n",
    "       'missing_values': data.isnull().sum().to_dict(),\n",
    "       'missing_percentage': (data.isnull().sum() / len(data) * 100).round(2).to_dict()\n",
    "   }\n",
    "   \n",
    "   if include_stats:\n",
    "       numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "       categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "       \n",
    "       if len(numeric_cols) > 0:\n",
    "           preview_info['numeric_statistics'] = data[numeric_cols].describe()\n",
    "       \n",
    "       if len(categorical_cols) > 0:\n",
    "           preview_info['categorical_info'] = {}\n",
    "           for col in categorical_cols:\n",
    "               preview_info['categorical_info'][col] = {\n",
    "                   'unique_count': data[col].nunique(),\n",
    "                   'top_values': data[col].value_counts().head().to_dict()\n",
    "               }\n",
    "   \n",
    "   return preview_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cf67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_overview(data: pd.DataFrame, target_column: str = None):\n",
    "   info = preview_data(data)\n",
    "   \n",
    "   print(\"=\" * 60)\n",
    "   print(\"DATASET OVERVIEW\")\n",
    "   print(\"=\" * 60)\n",
    "   print(f\"Shape: {info['dataset_shape'][0]} rows × {info['dataset_shape'][1]} columns\")\n",
    "   print(f\"Memory Usage: {info['memory_usage']}\")\n",
    "   print(f\"Columns: {', '.join(info['column_names'])}\")\n",
    "   \n",
    "   print(\"\\n\" + \"=\" * 60)\n",
    "   print(\"DATA TYPES\")\n",
    "   print(\"=\" * 60)\n",
    "   for col, dtype in info['data_types'].items():\n",
    "       print(f\"{col}: {dtype}\")\n",
    "   \n",
    "   print(\"\\n\" + \"=\" * 60)\n",
    "   print(\"MISSING VALUES\")\n",
    "   print(\"=\" * 60)\n",
    "   for col, missing in info['missing_values'].items():\n",
    "       percentage = info['missing_percentage'][col]\n",
    "       print(f\"{col}: {missing} ({percentage}%)\")\n",
    "   \n",
    "   if target_column and target_column in data.columns:\n",
    "       print(f\"\\n\" + \"=\" * 60)\n",
    "       print(f\"TARGET VARIABLE: {target_column}\")\n",
    "       print(\"=\" * 60)\n",
    "       print(data[target_column].value_counts())\n",
    "       print(f\"\\nClass Distribution:\")\n",
    "       print((data[target_column].value_counts() / len(data) * 100).round(2))\n",
    "   \n",
    "   print(f\"\\n\" + \"=\" * 60)\n",
    "   print(\"SAMPLE DATA (First 5 rows)\")\n",
    "   print(\"=\" * 60)\n",
    "   print(info['head_samples'])\n",
    "   \n",
    "   if 'categorical_info' in info:\n",
    "       print(f\"\\n\" + \"=\" * 60)\n",
    "       print(\"CATEGORICAL COLUMNS SUMMARY\")\n",
    "       print(\"=\" * 60)\n",
    "       for col, cat_info in info['categorical_info'].items():\n",
    "           print(f\"\\n{col}:\")\n",
    "           print(f\"  Unique values: {cat_info['unique_count']}\")\n",
    "           print(f\"  Top values: {cat_info['top_values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdc0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f88027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil diload: 1956 sampel\n",
      "Distribusi kelas:\n",
      "CLASS\n",
      "1    1005\n",
      "0     951\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = load_csv_data('../data/Youtube-Spam-Dataset.csv',\n",
    "                   text_column='CONTENT',\n",
    "                   label_column='CLASS',\n",
    "                   encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8710157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "Shape: 1956 rows × 6 columns\n",
      "Memory Usage: 0.87 MB\n",
      "Columns: COMMENT_ID, AUTHOR, DATE, CONTENT, VIDEO_NAME, CLASS\n",
      "\n",
      "============================================================\n",
      "DATA TYPES\n",
      "============================================================\n",
      "COMMENT_ID: object\n",
      "AUTHOR: object\n",
      "DATE: object\n",
      "CONTENT: object\n",
      "VIDEO_NAME: object\n",
      "CLASS: int64\n",
      "\n",
      "============================================================\n",
      "MISSING VALUES\n",
      "============================================================\n",
      "COMMENT_ID: 0 (0.0%)\n",
      "AUTHOR: 0 (0.0%)\n",
      "DATE: 245 (12.53%)\n",
      "CONTENT: 0 (0.0%)\n",
      "VIDEO_NAME: 0 (0.0%)\n",
      "CLASS: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "TARGET VARIABLE: CLASS\n",
      "============================================================\n",
      "CLASS\n",
      "1    1005\n",
      "0     951\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution:\n",
      "CLASS\n",
      "1    51.38\n",
      "0    48.62\n",
      "Name: count, dtype: float64\n",
      "\n",
      "============================================================\n",
      "SAMPLE DATA (First 5 rows)\n",
      "============================================================\n",
      "                                    COMMENT_ID            AUTHOR  \\\n",
      "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
      "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
      "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
      "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
      "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
      "\n",
      "                  DATE                                            CONTENT  \\\n",
      "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
      "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
      "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
      "3  2013-11-09T08:28:43  me shaking my sexy ass on my channel enjoy ^_^...   \n",
      "4  2013-11-10T16:05:38          watch?v=vtaRGgvGtWQ   Check this out .ï»¿   \n",
      "\n",
      "                       VIDEO_NAME  CLASS  \n",
      "0  PSY - GANGNAM STYLE(?????) M/V      1  \n",
      "1  PSY - GANGNAM STYLE(?????) M/V      1  \n",
      "2  PSY - GANGNAM STYLE(?????) M/V      1  \n",
      "3  PSY - GANGNAM STYLE(?????) M/V      1  \n",
      "4  PSY - GANGNAM STYLE(?????) M/V      1  \n",
      "\n",
      "============================================================\n",
      "CATEGORICAL COLUMNS SUMMARY\n",
      "============================================================\n",
      "\n",
      "COMMENT_ID:\n",
      "  Unique values: 1953\n",
      "  Top values: {'_2viQ_Qnc68fX3dYsfYuM-m4ELMJvxOQBmBOFHqGOk0': 2, 'LneaDw26bFuH6iFsSrjlJLJIX3qD4R8-emuZ-aGUj0o': 2, 'LneaDw26bFvPh9xBHNw1btQoyP60ay_WWthtvXCx37s': 2, 'LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU': 1, 'LneaDw26bFsTytWDcS_4DFWlbxAlCfw2c_9PIcArNdw': 1}\n",
      "\n",
      "AUTHOR:\n",
      "  Unique values: 1792\n",
      "  Top values: {'M.E.S': 8, '5000palo': 7, 'Louis Bryant': 7, 'Shadrach Grentz': 7, 'DanteBTV': 6}\n",
      "\n",
      "DATE:\n",
      "  Unique values: 1709\n",
      "  Top values: {'2013-10-05T00:57:25.078000': 2, '2014-11-07T19:33:46': 2, '2013-11-07T06:20:48': 1, '2014-07-21T11:05:51.945000': 1, '2015-05-28T21:50:26.114000': 1}\n",
      "\n",
      "CONTENT:\n",
      "  Unique values: 1760\n",
      "  Top values: {'Check out this video on YouTube:ï»¿': 97, 'Check out this playlist on YouTube:ï»¿': 21, 'Check Out The New Hot Video By Dante B Called Riled Up': 6, 'Shakira :-*': 4, 'Likeï»¿': 4}\n",
      "\n",
      "VIDEO_NAME:\n",
      "  Unique values: 5\n",
      "  Top values: {'Eminem - Love The Way You Lie ft. Rihanna': 448, 'LMFAO - Party Rock Anthem ft. Lauren Bennett, GoonRock': 438, 'Shakira - Waka Waka ': 370, 'PSY - GANGNAM STYLE(?????) M/V': 350, 'Katy Perry - Roar': 350}\n"
     ]
    }
   ],
   "source": [
    "display_data_overview(df, target_column='CLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706165a1",
   "metadata": {},
   "source": [
    "### 1.2.2 Convert Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5509066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(data: Union[str, pd.DataFrame, pd.Series, List[str], np.ndarray], \n",
    "                       column: str = None) -> Union[str, pd.DataFrame, pd.Series, List[str], np.ndarray]:\n",
    "   if isinstance(data, str):\n",
    "       return data.lower()\n",
    "   \n",
    "   elif isinstance(data, pd.DataFrame):\n",
    "       if column is None:\n",
    "           raise ValueError(\"Parameter 'column' harus diisi untuk DataFrame\")\n",
    "       result = data.copy()\n",
    "       result[column] = result[column].astype(str).str.lower()\n",
    "       return result\n",
    "   \n",
    "   elif isinstance(data, pd.Series):\n",
    "       return data.astype(str).str.lower()\n",
    "   \n",
    "   elif isinstance(data, list):\n",
    "       return [str(text).lower() for text in data]\n",
    "   \n",
    "   elif isinstance(data, np.ndarray):\n",
    "       return np.array([str(text).lower() for text in data])\n",
    "   \n",
    "   else:\n",
    "       raise TypeError(f\"Tipe data {type(data)} tidak didukung\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e20faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    huh, anyway check out this you[tube] channel: ...\n",
       "1    hey guys check out my new channel and our firs...\n",
       "2               just for test i have to say murdev.com\n",
       "3    me shaking my sexy ass on my channel enjoy ^_^...\n",
       "4            watch?v=vtarggvgtwq   check this out .ï»¿\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_df = convert_to_lowercase(df, column='CONTENT')\n",
    "converted_df['CONTENT'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbff5c",
   "metadata": {},
   "source": [
    "### 1.2.4 remove_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c3a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "    '''Remove unwanted characters while preserving important features for spam/ham classification'''\n",
    "    \n",
    "    if not text or pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Decode HTML entities like &amp;, &lt;, &gt;\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Remove HTML tags first\n",
    "    text = re.sub(r'<[^>]*>', ' ', text)\n",
    "    \n",
    "    # Replace emails with token\n",
    "    text = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', ' EMAILADDRESS ', text)\n",
    "    \n",
    "    # Crypto/wallet addresses (long random strings)\n",
    "    text = re.sub(r'\\b[a-zA-Z0-9]{25,}\\b', ' CRYPTOADDRESS ', text)\n",
    "\n",
    "    # Handle spaced domains BEFORE general URL detection\n",
    "    # \"kidsmediausa .com\" → \"kidsmediausa.com\" (more targeted)\n",
    "    text = re.sub(\n",
    "    r'([a-zA-Z0-9_-]+)\\s*\\.\\s*(com|net|org|id|co|uk|info|biz)\\s*(/[^\\s]*)?', 'URL',\n",
    "    text)\n",
    "\n",
    "    text = re.sub(\n",
    "    r'\\b(?:https?://|www\\.)?[\\w.-]+\\.[a-z]{2,}(?:/[^\\s]*)*',\n",
    "    ' URL ',\n",
    "    text,\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "    # Replace URLs with contextual tokens (preserve the spam signal)\n",
    "    # Full URLs\n",
    "    text = re.sub(\n",
    "        r'''(?ix)\n",
    "        \\b(?:https?:?/?/?|http:?/?/?|www\\.)\n",
    "        [\\w\\-]+(\\.[\\w\\-.]+)+\n",
    "        (/[^\\s]*)?\n",
    "        ''',\n",
    "        ' URL ',\n",
    "        text\n",
    "    )\n",
    "    \n",
    "    # Shortened URLs\n",
    "    text = re.sub(\n",
    "        r'\\b(?:bit|adf|tinyurl|rebrand|shorturl|is\\.gd|shorte|cutt|t\\.co|lnkd)\\.(?:ly|me|com|co|gd|io)(?:/\\S*)?',\n",
    "        ' URL ',\n",
    "        text\n",
    "    )\n",
    "    \n",
    "    # YouTube video links\n",
    "    text = re.sub(r'watch\\?v=\\S+', ' URL ', text)\n",
    "    \n",
    "    # Domain-only patterns (common in spam)\n",
    "    text = re.sub(r'\\b[a-zA-Z0-9_-]+\\.(?:com|net|org|id|co|uk)\\b', ' URL ', text)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Replace ordinal numbers\n",
    "    text = re.sub(r'\\b\\d+(st|nd|rd|th)\\b', 'NUM', text)\n",
    "    \n",
    "    # Replace various number formats with more specific tokens\n",
    "    # Ganti semua angka dan angka+huruf satuan menjadi NUM\n",
    "    text = re.sub(\n",
    "    r'\\b\\d+(\\.\\d+)?([eE][+-]?\\d+)?([a-zA-Z]+)?\\b',\n",
    "    'NUM',\n",
    "    text)\n",
    "\n",
    "    # Remove repetitive symbols (e.g., â–Œ repeated multiple times)\n",
    "    text = re.sub(r'(\\W)\\1+', r'\\1', text)  # Replace repeated non-word characters with a single one\n",
    "\n",
    "    # Hapus emotikon seperti :) :p :( :D :-P dll\n",
    "    text = re.sub(r'[:;=xX8][-~^]?[)(dDPpOo3|/\\\\]', ' ', text)\n",
    "\n",
    "    # Fix separated letters but preserve intentional spacing for emphasis\n",
    "    # \"d-d-d-d\" → \"dddd\" (stammering pattern)\n",
    "    text = re.sub(r'\\b([a-zA-Z])-([a-zA-Z])-([a-zA-Z]+(?:-[a-zA-Z])*)\\b', \n",
    "                  lambda m: m.group(0).replace('-', ''), text)\n",
    "    \n",
    "    # \"p e a c e\" → \"peace\" but only if it's clearly unintentional\n",
    "    text = re.sub(r'\\b([a-zA-Z])\\s+([a-zA-Z])\\s+([a-zA-Z])\\s+([a-zA-Z]+(?:\\s+[a-zA-Z])*)\\b',\n",
    "                  lambda m: m.group(0).replace(' ', ''), text)\n",
    "    \n",
    "    # Remove BOM and problematic Unicode\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    \n",
    "    # Remove BOM and all non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Removes characters like ï»¿ or emojis\n",
    "    \n",
    "    # Clean up excessive special characters (but keep our tokens)\n",
    "    # Remove everything except letters, numbers, spaces, and our preserved tokens\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Normalize repeated characters (but preserve our spam indicators)\n",
    "    # \"hellooooo\" → \"helloo\" (reduce but don't eliminate completely)\n",
    "    text = re.sub(r'([a-zA-Z])\\1{3,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Consolidate multiple instances of our tokens\n",
    "    text = re.sub(r'\\b(NUM)(\\s+\\1)+\\b', r'\\1', text)\n",
    "    \n",
    "    # Final whitespace cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a14c6",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc6d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
